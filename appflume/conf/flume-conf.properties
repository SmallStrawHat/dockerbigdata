############################################
# producer config
###########################################

#agent section
producer.sources = s snc
producer.channels = c
producer.sinks = r

#source section
###netcat###
producer.sources.snc.type = netcat
producer.sources.snc.channels = c
producer.sources.snc.bind = 0.0.0.0
producer.sources.snc.port = 44444
producer.sources.snc.max-line-length = 4096
###nginx###
#warning: there is absolutely zero guarantee of event delivery when using this source
producer.sources.s.type = exec
producer.sources.s.command = tail -n0 -F /data/log/nginx/access.log
producer.sources.s.channels = c
###Spooling Directory Source###
#Unlike the Exec source, this source is reliable and will not miss data, even if Flume is restarted or killed. 
#producer.sources.s.type = spooldir
#producer.sources.s.spoolDir = /tmp/test/
#producer.sources.s.deserializer.maxLineLength = 4096

# Each sink's type must be defined
producer.sinks.r.type = org.apache.flume.plugins.KafkaSink
producer.sinks.r.metadata.broker.list=kafka:9092
producer.sinks.r.partition.key=0
producer.sinks.r.partitioner.class=org.apache.flume.plugins.SinglePartition
producer.sinks.r.serializer.class=kafka.serializer.StringEncoder
producer.sinks.r.request.required.acks=0
producer.sinks.r.max.message.size=1000000000
producer.sinks.r.producer.type=sync
producer.sinks.r.custom.encoding=UTF-8
producer.sinks.r.custom.topic.name=test

#Specify the channel the sink should use
producer.sinks.r.channel = c

# Each channel's type is defined.
producer.channels.c.type = memory
producer.channels.c.capacity = 1000000
producer.channels.c.transactionCapacity = 100000
producer.channels.c.byteCapacityBufferPercentage = 40
producer.channels.c.byteCapacity = 8000000
